{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ RAG with LangChain, Sentence Transformers, and FAISS\n",
                "\n",
                "Yo, bro! Ready to build a dope Retrieval-Augmented Generation (RAG) system? üòé\n",
                "We‚Äôre using **LangChain**, **Sentence Transformers**, and **FAISS** to answer questions with context from a text file, powered by HuggingFace‚Äôs flan-t5-base ‚Äî all free, no APIs! üéâ\n",
                "This is step 5 of your learning path, so let‚Äôs dive in and make some AI magic! ‚ú®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 1: Install dependencies\n",
                "!pip install -q sentence-transformers faiss-cpu transformers langchain unstructured pdfminer.six"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 2: Imports\n",
                "import os\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from transformers import pipeline\n",
                "import faiss\n",
                "import numpy as np\n",
                "from langchain.text_splitter import CharacterTextSplitter\n",
                "from langchain.document_loaders import TextLoader\n",
                "print(\"üéâ Libraries loaded ‚Äî ready to roll!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 3: Load your document\n",
                "with open(\"sample_text.txt\", \"w\") as f:\n",
                "    f.write(\"\"\"\n",
                "    Artificial Intelligence (AI) is transforming industries by enabling machines to learn, reason, and interact with humans. Retrieval-Augmented Generation (RAG) combines the power of large language models with external knowledge bases to provide accurate and context-aware responses. FAISS, developed by Facebook AI, is a highly efficient library for similarity search and clustering of dense vectors. It is widely used for building vector databases in RAG pipelines. HuggingFace provides open-source models like flan-t5-base, which are perfect for question answering without needing expensive APIs.\n",
                "    \"\"\")\n",
                "\n",
                "loader = TextLoader(\"sample_text.txt\")\n",
                "documents = loader.load()\n",
                "print(\"üìÑ Document loaded ‚Äî time to chunk it up!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 4: Chunk the text\n",
                "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
                "chunks = text_splitter.split_documents(documents)\n",
                "texts = [chunk.page_content for chunk in chunks]\n",
                "print(\"‚úÇÔ∏è Text chunked into\", len(texts), \"pieces ‚Äî ready for embedding!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 5: Embed with Sentence Transformers\n",
                "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
                "embeddings = model.encode(texts, show_progress_bar=True)\n",
                "print(\"üß† Embeddings created ‚Äî let‚Äôs store them in FAISS!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 6: Store in FAISS index\n",
                "dim = embeddings[0].shape[0]\n",
                "index = faiss.IndexFlatL2(dim)\n",
                "index.add(np.array(embeddings))\n",
                "print(\"üìä FAISS index built ‚Äî ready to search for answers!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 7: Setup Question Answering pipeline\n",
                "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
                "print(\"ü§ñ QA pipeline with flan-t5-base loaded ‚Äî let‚Äôs ask some questions!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 8: Ask a question\n",
                "query = \"What is RAG?\"\n",
                "query_embedding = model.encode([query])\n",
                "D, I = index.search(np.array(query_embedding), k=3)\n",
                "\n",
                "context = \"\\n\".join([texts[i] for i in I[0]])\n",
                "prompt = f\"Answer the question based on context:\\n{context}\\n\\nQ: {query}\\nA:\"\n",
                "\n",
                "result = qa_pipeline(prompt, max_length=100)[0]['generated_text']\n",
                "print(\"Q:\", query)\n",
                "print(\"A:\", result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìö Tips for Having Fun\n",
                "- Try a different question in Step 8, like \"What is FAISS?\" or \"What does HuggingFace do?\"\n",
                "- Upload your own text file in Step 3 instead of `sample_text.txt`.\n",
                "- Play with chunk size in Step 4 (e.g., `chunk_size=100`) for more or fewer chunks.\n",
                "- Check out HuggingFace‚Äôs docs (https://huggingface.co/docs) or LangChain‚Äôs docs (https://python.langchain.com/docs) for more RAG tricks!\n",
                "\n",
                "# üöÄ What‚Äôs Next?\n",
                "- Save this as your fifth notebook in your learning path.\n",
                "- Combine with your DistilBERT notebook (step 4) for a sentiment + RAG project!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

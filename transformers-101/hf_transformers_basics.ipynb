{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ðŸ¤— Transformers 101 â€” HuggingFace Quickstart\n",
        "# ðŸ“˜ Notebook: Learn to use HuggingFace Transformers pipelines for common NLP tasks\n",
        "# ðŸ”§ Designed to run in Google Colab with free models\n",
        "\n",
        "# âœ… Step 1: Install the library\n",
        "!pip install -q transformers\n",
        "\n",
        "# âœ… Step 2: Import libraries\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# âœ… Step 3: Check for GPU availability\n",
        "device = 0 if torch.cuda.is_available() else -1  # Use GPU (0) if available, else CPU (-1)\n",
        "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "# ðŸ”¹ Helper function to run pipelines and handle errors\n",
        "def run_pipeline(pipeline_obj, input_data, **kwargs):\n",
        "    try:\n",
        "        result = pipeline_obj(input_data, **kwargs)[0]\n",
        "        print(f\"\\nInput:\\n{input_data}\\n\\nResult:\\n{result}\\n\")\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"\\nInput:\\n{input_data}\\n\\nError:\\n{str(e)}\\n\")\n",
        "        return None\n",
        "\n",
        "# ---\n",
        "# ðŸ”¹ Example 1: Text Generation (Translation)\n",
        "# ðŸ“ Translate a sentence using flan-t5-base\n",
        "text_gen = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=device)\n",
        "prompt = \"Translate to German: I love natural language processing.\"\n",
        "run_pipeline(text_gen, prompt, max_new_tokens=50)\n",
        "\n",
        "# ðŸ”¹ Example 2: Summarization\n",
        "# ðŸ“ Summarize a paragraph using distilbart\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=device)\n",
        "long_text = \"\"\"\n",
        "Transformers are a type of deep learning model that have revolutionized natural language processing by enabling models to learn contextual relationships between words in a text.\n",
        "\"\"\"\n",
        "run_pipeline(summarizer, long_text, max_length=20, min_length=10)\n",
        "\n",
        "# ðŸ”¹ Example 3: Question Answering\n",
        "# ðŸ“ Answer a question based on context\n",
        "qa = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\", device=device)\n",
        "context = \"HuggingFace Transformers provide thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, and more.\"\n",
        "question = \"What tasks can HuggingFace Transformers perform?\"\n",
        "run_pipeline(qa, {\"question\": question, \"context\": context})\n",
        "\n",
        "# ðŸ”¹ Example 4: Sentiment Analysis\n",
        "# ðŸ“ Analyze sentiment of a sentence\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=device)\n",
        "text = \"This notebook is amazing!\"\n",
        "run_pipeline(sentiment, text)\n",
        "\n",
        "# ðŸ”¹ Example 5: Named Entity Recognition (NER)\n",
        "# ðŸ“ Identify entities in a sentence\n",
        "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\", device=device)\n",
        "text = \"HuggingFace is based in New York and was founded by ClÃ©ment Delangue.\"\n",
        "run_pipeline(ner, text)\n",
        "\n",
        "# ---\n",
        "# ðŸ“š Tips for Using This Notebook\n",
        "# 1. Run in Colab with GPU enabled (Runtime > Change runtime type > GPU) for faster inference.\n",
        "# 2. Experiment with different inputs or models (e.g., google/flan-t5-large for text generation).\n",
        "# 3. Check model cards on HuggingFace (e.g., https://huggingface.co/google/flan-t5-base) for task suitability.\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zdNt3f8bau25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
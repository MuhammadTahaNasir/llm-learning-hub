# ğŸ” Free RAG Pipeline: HuggingFace Transformers + FAISS + Sentence Transformers

<p align="center">
  <img src="https://img.shields.io/badge/RAG-ready-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/FAISS-VectorDB-green?style=flat-square" />
  <img src="https://img.shields.io/badge/HuggingFace-ğŸ¤—-yellow?style=flat-square" />
</p>

> ğŸ’¡ Build a Retrieval-Augmented Generation (RAG) pipeline with **no paid APIs**.  
> Embed, store, and query your documents locally using FAISS and HuggingFace â€” 100% free & open source.

---

## ğŸ§  What is This?

A minimal, efficient **RAG (Retrieval-Augmented Generation)** system using only:
- ğŸ§  [SentenceTransformers](https://www.sbert.net/) for embedding documents
- ğŸ” [FAISS](https://faiss.ai/) for local vector search
- ğŸ¤– [FLAN-T5](https://huggingface.co/google/flan-t5-base) via HuggingFace Transformers as the language model

No OpenAI, no Pinecone, no paid APIs.

---

## ğŸ“‚ Project Structure

```
free_rag_pipeline_faiss/
â”œâ”€â”€ streamlit_app.py          # Streamlit frontend (optional)
â”œâ”€â”€ free_rag_pipeline.ipynb   # Colab-ready notebook
â”œâ”€â”€ example.txt               # Sample document (can be replaced with PDF)
â””â”€â”€ README.md                 # You're here
```

---

## ğŸš€ Features

- âœ… 100% free & offline-compatible
- âœ… HuggingFace open-source models only
- âœ… Local vector DB using FAISS
- âœ… Document chunking + embedding with `all-MiniLM-L6-v2`
- âœ… Context-aware question answering via `flan-t5-base`

---

## ğŸ”§ How It Works

1. **Load a document** (text, PDF, or scraped data)
2. **Split into chunks** using LangChain's `TextSplitter`
3. **Generate embeddings** with `sentence-transformers`
4. **Store in FAISS index** locally
5. **Query with a user question** â†’ retrieve top-K chunks
6. **Prompt the LLM** with retrieved context using `google/flan-t5-base`

---

## ğŸ“Š Example

```python
Q: What is LangChain?
A: LangChain is a framework for building applications powered by language models and external tools like APIs and vector databases.
```

---

## ğŸ› ï¸ Requirements

```bash
pip install sentence-transformers faiss-cpu transformers langchain unstructured pdfminer.six
```

> ğŸ’¡ Use inside [Google Colab](https://colab.research.google.com) for best results (GPU acceleration optional but helpful).

---

## ğŸ“˜ Future Add-ons

- [ ] PDF upload support via `Unstructured` or `PyMuPDF`
- [ ] Switchable models (e.g., Mistral, LLaMA 3 via Transformers)
- [ ] Add ChromaDB backend as alternative to FAISS

---

## ğŸŒ Try the Streamlit App

### ğŸ–¼ï¸ Live App Preview

![Streamlit App Screenshot](streamlit_preview.png)


You can test the full pipeline using a simple UI built with [Streamlit](https://streamlit.io). Upload a text file, ask a question, and get context-aware answers from a local model.

> ğŸ“ Run it locally with:
```bash
streamlit run streamlit_app.py
```

> ğŸ§  No OpenAI or paid APIs used â€” 100% free using HuggingFace + FAISS.

> ğŸ“ File: `streamlit_app.py`

---

## ğŸ¤ Contributing

Contributions welcome, fork this repo, improve the pipeline, or try new models!  
If you like it, consider â­ï¸ starring and sharing.

---

## ğŸ“« Author

**Muhammad Taha Nasir**  
ğŸ’¼ Aspiring AI Engineer | RAG Systems | Open Source  
ğŸŒ [LinkedIn](https://linkedin.com/muhammadtahanasir) Â· [GitHub](https://github.com/MuhammadTahaNasir) Â· [Kaggle](https://kaggle.com/muhamadtahanasir)

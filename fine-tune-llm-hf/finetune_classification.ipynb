{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† Fine-Tune a Transformer (HuggingFace Trainer)\n",
                "\n",
                "Yo, bro! Ready to teach a model to vibe with movie reviews? üòé\n",
                "We‚Äôre fine-tuning **DistilBERT** on the IMDB dataset for sentiment analysis ‚Äî positive or negative, let‚Äôs find out! üé¨\n",
                "This is step 4 of your learning path, so let‚Äôs make this model a movie critic star! üåü"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 1: Install the tools we need\n",
                "# Grabbing HuggingFace‚Äôs transformers, datasets, and evaluate for metrics. Let‚Äôs roll!\n",
                "try:\n",
                "    !pip install -q transformers==4.41.2 datasets==2.20.0 evaluate==0.4.3 fsspec==2024.6.0\n",
                "    print(\"üéâ Libraries installed ‚Äî ready to make some magic!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Installation failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 2: Clear cache to avoid loading issues\n",
                "# Let‚Äôs start fresh to dodge any pesky cache errors!\n",
                "try:\n",
                "    import shutil\n",
                "    import os\n",
                "    cache_dir = \"/root/.cache/huggingface\"\n",
                "    if os.path.exists(cache_dir):\n",
                "        shutil.rmtree(cache_dir)\n",
                "        print(\"üßπ Cleared cache to start fresh!\")\n",
                "    os.makedirs(cache_dir, exist_ok=True)\n",
                "except Exception as e:\n",
                "    print(f\"üòï Cache clearing failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 3: Import the goodies\n",
                "# Loading libraries to make fine-tuning and evaluation a breeze.\n",
                "try:\n",
                "    import torch\n",
                "    import os\n",
                "    from datasets import load_dataset, Dataset, DatasetDict\n",
                "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
                "    import evaluate\n",
                "    import pandas as pd\n",
                "    print(\"üõ†Ô∏è Libraries imported ‚Äî let‚Äôs get to work!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Import failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 4: Check for GPU (faster training!)\n",
                "# Let‚Äôs see if we can speed things up with a GPU.\n",
                "try:\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    print(f\"üöÄ Running on {device} ‚Äî let‚Äôs make it happen!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Device check failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 5: Download and load the IMDB dataset manually\n",
                "# Downloading the dataset files directly to avoid issues with load_dataset(\"imdb\").\n",
                "try:\n",
                "    if not os.path.exists(\"aclImdb\"):\n",
                "        !wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
                "        !tar -xf aclImdb_v1.tar.gz\n",
                "        print(\"\\nContents of aclImdb directory after extraction:\")\n",
                "        !ls aclImdb\n",
                "    else:\n",
                "        print(\"‚úÖ Dataset directory 'aclImdb' already exists.\")\n",
                "\n",
                "    def load_imdb_data(directory):\n",
                "        reviews = []\n",
                "        labels = []\n",
                "        for label in ['pos', 'neg']:\n",
                "            subdir = os.path.join(directory, label)\n",
                "            for filename in os.listdir(subdir):\n",
                "                if filename.endswith(\".txt\"):\n",
                "                    with open(os.path.join(subdir, filename), 'r', encoding='utf-8') as f:\n",
                "                        reviews.append(f.read())\n",
                "                    labels.append(1 if label == 'pos' else 0)\n",
                "        return pd.DataFrame({'text': reviews, 'label': labels})\n",
                "\n",
                "    train_df = load_imdb_data(\"aclImdb/train\")\n",
                "    test_df = load_imdb_data(\"aclImdb/test\")\n",
                "\n",
                "    train_dataset = Dataset.from_pandas(train_df)\n",
                "    test_dataset = Dataset.from_pandas(test_df)\n",
                "\n",
                "    dataset = DatasetDict({\n",
                "        'train': train_dataset,\n",
                "        'test': test_dataset\n",
                "    })\n",
                "    print(f\"üìö Loaded IMDB dataset with {len(dataset['train'])} train and {len(dataset['test'])} test samples!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Failed to load dataset: {e}\")\n",
                "    print(\"üëâ Try restarting Colab (Runtime > Restart session) or checking your internet.\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 6: Grab a smaller chunk to keep Colab happy\n",
                "# Using 2000 train and 1000 test samples to avoid memory hiccups.\n",
                "try:\n",
                "    small_train = dataset['train'].shuffle(seed=42).select(range(2000))\n",
                "    small_test = dataset['test'].shuffle(seed=42).select(range(1000))\n",
                "    print(f\"‚úÇÔ∏è Using {len(small_train)} train and {len(small_test)} test samples ‚Äî nice and lightweight!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Failed to split dataset: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 7: Load tokenizer and model\n",
                "# DistilBERT is a speedy, small version of BERT ‚Äî perfect for Colab‚Äôs free tier.\n",
                "try:\n",
                "    model_ckpt = \"distilbert-base-uncased\"\n",
                "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
                "    model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=2).to(device)\n",
                "    print(\"üß† Loaded DistilBERT model and tokenizer ‚Äî ready to learn those reviews!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Failed to load model/tokenizer: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 8: Tokenize the reviews\n",
                "# Turning text into numbers the model can understand (like teaching it movie lingo).\n",
                "try:\n",
                "    def tokenize_fn(batch):\n",
                "        return tokenizer(batch['text'], padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
                "    tokenized_train = small_train.map(tokenize_fn, batched=True)\n",
                "    tokenized_test = small_test.map(tokenize_fn, batched=True)\n",
                "    print(\"‚ú® Tokenized datasets ‚Äî we're speaking DistilBERT‚Äôs language now!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Tokenization failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 9: Set up accuracy metric\n",
                "# Let‚Äôs measure how well our model predicts positive vs. negative vibes.\n",
                "try:\n",
                "    accuracy = evaluate.load('accuracy')\n",
                "    def compute_metrics(eval_pred):\n",
                "        logits, labels = eval_pred\n",
                "        preds = torch.argmax(torch.tensor(logits, device=device), axis=1)\n",
                "        return accuracy.compute(predictions=preds.cpu().numpy(), references=labels)\n",
                "    print(\"üìä Accuracy metric ready ‚Äî ready to check our score!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Failed to load metric: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 10: Set up the training pipeline\n",
                "# This is our study plan for DistilBERT to learn the movie review game.\n",
                "try:\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir='./results',\n",
                "        eval_strategy='epoch',\n",
                "        save_strategy='epoch',\n",
                "        per_device_train_batch_size=8,\n",
                "        per_device_eval_batch_size=8,\n",
                "        num_train_epochs=2,\n",
                "        logging_dir='./logs',\n",
                "        logging_steps=10,\n",
                "        load_best_model_at_end=True,\n",
                "        metric_for_best_model='accuracy',\n",
                "        report_to='none'\n",
                "    )\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        train_dataset=tokenized_train,\n",
                "        eval_dataset=tokenized_test,\n",
                "        compute_metrics=compute_metrics\n",
                "    )\n",
                "    print(\"‚öôÔ∏è Training pipeline ready ‚Äî time to train like a champ!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Failed to set up trainer: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 11: Train the model\n",
                "# Let‚Äôs teach DistilBERT to predict those movie review sentiments!\n",
                "try:\n",
                "    trainer.train()\n",
                "    print(\"üéâ Training complete ‚Äî our model‚Äôs got some serious movie review skills now!\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Training failed: {e}\")\n",
                "    print(\"üëâ Try reducing batch size to 4 or restarting Colab if memory runs out!\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 12: Evaluate the model\n",
                "# How good is our model at predicting sentiments? Let‚Äôs find out!\n",
                "try:\n",
                "    results = trainer.evaluate()\n",
                "    print(f\"\\nüìà Evaluation results: {results}\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Evaluation failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚úÖ Step 13: Test with your own review\n",
                "# Throw in a movie review and see what the model thinks!\n",
                "try:\n",
                "    test_review = \"I absolutely loved this movie, it was fantastic!\"\n",
                "    inputs = tokenizer(test_review, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
                "    outputs = model(**inputs)\n",
                "    prediction = outputs.logits.argmax().item()\n",
                "    print(f\"\\nüé• Your review: '{test_review}'\")\n",
                "    print(f\"ü§ñ Prediction: {'Positive' if prediction == 1 else 'Negative'}\")\n",
                "except Exception as e:\n",
                "    print(f\"üòï Prediction failed: {e}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìö Tips for Having Fun\n",
                "- Got a GPU? Try a bigger dataset (e.g., 5000 train samples) in Step 6.\n",
                "- Play with Step 13: Test reviews like \"This movie was awful!\" or your own.\n",
                "- Want a bigger model? Swap to bert-base-uncased in Step 7 (needs more memory).\n",
                "- Dive into HuggingFace‚Äôs Trainer docs (https://huggingface.co/docs/transformers/main_classes/trainer) for pro tips!\n",
                "\n",
                "# üöÄ What‚Äôs Next?\n",
                "- Save this as your fourth notebook in your learning path.\n",
                "- Use this model in your LLM Evaluation notebook (step 3) to check its outputs.\n",
                "- Explore RAG with LangChain/ChromaDB or Weaviate (steps 5‚Äì6) for more fun!\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

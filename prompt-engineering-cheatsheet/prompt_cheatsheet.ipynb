# ğŸ§  Prompt Engineering Cheatsheet (Free, HuggingFace LLMs)
# ğŸ“˜ Notebook: Learn and test prompt engineering techniques using a free LLM
# ğŸ”§ Designed to run in Google Colab with no API key required

# âœ… Step 1: Install transformers
!pip install -q transformers

# âœ… Step 2: Import libraries
import torch
from transformers import pipeline

# âœ… Step 3: Check for GPU availability
device = 0 if torch.cuda.is_available() else -1  # Use GPU (0) if available, else CPU (-1)
print(f"Using device: {'GPU' if device == 0 else 'CPU'}")

# âœ… Step 4: Load a FREE small LLM (flan-t5-base)
llm = pipeline("text2text-generation", model="google/flan-t5-base", device=device)

# ğŸ”¹ Helper function to run prompts and display results
def ask(prompt):
    try:
        res = llm(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']
        print(f"\nPrompt:\n{prompt}\n\nResponse:\n{res}\n")
    except Exception as e:
        print(f"\nPrompt:\n{prompt}\n\nError:\n{str(e)}\n")

# ---
# ğŸ§ª 1. Zero-shot Prompt
# ğŸ“ Directly ask the model to perform a task without examples
ask("Translate to French: I love machine learning.")

# ğŸ§ª 2. Few-shot Prompt
# ğŸ“ Provide examples to guide the model
few_shot = """Translate to emoji:
"I love you" -> â¤ï¸
"Good job" -> ğŸ‘
"I'm angry" -> ğŸ˜£
Task: Translate "I'm happy" to emoji."""
ask(few_shot)

# ğŸ§ª 3. Instruction Prompt
# ğŸ“ Give a clear instruction for a specific task
ask("Summarize in one sentence: Transformers are models that use self-attention to understand sentence context and are widely used in NLP tasks.")

# ğŸ§ª 4. Chain of Thought Prompt
# ğŸ“ Encourage step-by-step reasoning (simplified for flan-t5-base)
cot = """Solve step by step: Two trains are 420km apart. Train A travels at 60km/h, and Train B travels at 80km/h toward each other. How long until they meet?
1. Calculate the combined speed.
2. Divide the distance by the combined speed to find the time."""
ask(cot)

# ğŸ§ª 5. Role Prompting
# ğŸ“ Assign a role to shape response style
ask("As a friendly teacher, explain in simple terms: What is a neural network?")

# ğŸ§ª 6. Custom Style Prompt
# ğŸ“ Specify a tone for the response
ask("Write a professional email response to: 'hey, i need help with my code asap'.")

# ğŸ§ª 7. JSON Format Output Prompt
# ğŸ“ Request structured output (simplified for flan-t5-base)
ask("List 3 cities with their countries in JSON format. Example: [{'city': 'Paris', 'country': 'France'}].")

# ğŸ§ª 8. Creative Prompt (Simplified)
# ğŸ“ Simple creative task suited for flan-t5-base
ask("Write a short sentence describing artificial intelligence in a futuristic tone.")

# ---
# ğŸ“š Tips for Using This Cheatsheet
# 1. Run each prompt in Colab to see how flan-t5-base responds.
# 2. Experiment by tweaking prompts (e.g., add more examples, change instructions).
# 3. Note: flan-t5-base is small and may struggle with complex tasks. For better results, try 'google/flan-t5-large' (if Colab memory allows).
# 4. Save this notebook in Colab for future reference!

# ğŸš€ Next Steps
# - âœ… Run this notebook in Colab and save it.
# - Explore HuggingFace Transformers 101 to learn more about LLMs.
# - Learn LLM evaluation to assess model performance.

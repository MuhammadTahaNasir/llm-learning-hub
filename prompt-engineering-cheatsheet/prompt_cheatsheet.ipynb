# 🧠 Prompt Engineering Cheatsheet (Free, HuggingFace LLMs)
# 📘 Notebook: Learn and test prompt engineering techniques using a free LLM
# 🔧 Designed to run in Google Colab with no API key required

# ✅ Step 1: Install transformers
!pip install -q transformers

# ✅ Step 2: Import libraries
import torch
from transformers import pipeline

# ✅ Step 3: Check for GPU availability
device = 0 if torch.cuda.is_available() else -1  # Use GPU (0) if available, else CPU (-1)
print(f"Using device: {'GPU' if device == 0 else 'CPU'}")

# ✅ Step 4: Load a FREE small LLM (flan-t5-base)
llm = pipeline("text2text-generation", model="google/flan-t5-base", device=device)

# 🔹 Helper function to run prompts and display results
def ask(prompt):
    try:
        res = llm(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']
        print(f"\nPrompt:\n{prompt}\n\nResponse:\n{res}\n")
    except Exception as e:
        print(f"\nPrompt:\n{prompt}\n\nError:\n{str(e)}\n")

# ---
# 🧪 1. Zero-shot Prompt
# 📝 Directly ask the model to perform a task without examples
ask("Translate to French: I love machine learning.")

# 🧪 2. Few-shot Prompt
# 📝 Provide examples to guide the model
few_shot = """Translate to emoji:
"I love you" -> ❤️
"Good job" -> 👍
"I'm angry" -> 😣
Task: Translate "I'm happy" to emoji."""
ask(few_shot)

# 🧪 3. Instruction Prompt
# 📝 Give a clear instruction for a specific task
ask("Summarize in one sentence: Transformers are models that use self-attention to understand sentence context and are widely used in NLP tasks.")

# 🧪 4. Chain of Thought Prompt
# 📝 Encourage step-by-step reasoning (simplified for flan-t5-base)
cot = """Solve step by step: Two trains are 420km apart. Train A travels at 60km/h, and Train B travels at 80km/h toward each other. How long until they meet?
1. Calculate the combined speed.
2. Divide the distance by the combined speed to find the time."""
ask(cot)

# 🧪 5. Role Prompting
# 📝 Assign a role to shape response style
ask("As a friendly teacher, explain in simple terms: What is a neural network?")

# 🧪 6. Custom Style Prompt
# 📝 Specify a tone for the response
ask("Write a professional email response to: 'hey, i need help with my code asap'.")

# 🧪 7. JSON Format Output Prompt
# 📝 Request structured output (simplified for flan-t5-base)
ask("List 3 cities with their countries in JSON format. Example: [{'city': 'Paris', 'country': 'France'}].")

# 🧪 8. Creative Prompt (Simplified)
# 📝 Simple creative task suited for flan-t5-base
ask("Write a short sentence describing artificial intelligence in a futuristic tone.")

# ---
# 📚 Tips for Using This Cheatsheet
# 1. Run each prompt in Colab to see how flan-t5-base responds.
# 2. Experiment by tweaking prompts (e.g., add more examples, change instructions).
# 3. Note: flan-t5-base is small and may struggle with complex tasks. For better results, try 'google/flan-t5-large' (if Colab memory allows).
# 4. Save this notebook in Colab for future reference!

# 🚀 Next Steps
# - ✅ Run this notebook in Colab and save it.
# - Explore HuggingFace Transformers 101 to learn more about LLMs.
# - Learn LLM evaluation to assess model performance.

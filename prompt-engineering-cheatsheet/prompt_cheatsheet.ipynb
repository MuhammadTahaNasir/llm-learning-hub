{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§  Prompt Engineering Cheatsheet (Free, HuggingFace LLMs)\n",
        "# ðŸ“˜ Notebook: Learn and test prompt engineering techniques using a free LLM\n",
        "# ðŸ”§ Designed to run in Google Colab with no API key required\n",
        "\n",
        "# âœ… Step 1: Install transformers\n",
        "!pip install -q transformers\n",
        "\n",
        "# âœ… Step 2: Import libraries\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# âœ… Step 3: Check for GPU availability\n",
        "device = 0 if torch.cuda.is_available() else -1  # Use GPU (0) if available, else CPU (-1)\n",
        "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
        "\n",
        "# âœ… Step 4: Load a FREE small LLM (flan-t5-base)\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=device)\n",
        "\n",
        "# ðŸ”¹ Helper function to run prompts and display results\n",
        "def ask(prompt):\n",
        "    try:\n",
        "        res = llm(prompt, max_new_tokens=128, do_sample=False)[0]['generated_text']\n",
        "        print(f\"\\nPrompt:\\n{prompt}\\n\\nResponse:\\n{res}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nPrompt:\\n{prompt}\\n\\nError:\\n{str(e)}\\n\")\n",
        "\n",
        "# ---\n",
        "# ðŸ§ª 1. Zero-shot Prompt\n",
        "# ðŸ“ Directly ask the model to perform a task without examples\n",
        "ask(\"Translate to French: I love machine learning.\")\n",
        "\n",
        "# ðŸ§ª 2. Few-shot Prompt\n",
        "# ðŸ“ Provide examples to guide the model\n",
        "few_shot = \"\"\"Translate to emoji:\n",
        "\"I love you\" -> â¤ï¸\n",
        "\"Good job\" -> ðŸ‘\n",
        "\"I'm angry\" -> ðŸ˜£\n",
        "Task: Translate \"I'm happy\" to emoji.\"\"\"\n",
        "ask(few_shot)\n",
        "\n",
        "# ðŸ§ª 3. Instruction Prompt\n",
        "# ðŸ“ Give a clear instruction for a specific task\n",
        "ask(\"Summarize in one sentence: Transformers are models that use self-attention to understand sentence context and are widely used in NLP tasks.\")\n",
        "\n",
        "# ðŸ§ª 4. Chain of Thought Prompt\n",
        "# ðŸ“ Encourage step-by-step reasoning (simplified for flan-t5-base)\n",
        "cot = \"\"\"Solve step by step: Two trains are 420km apart. Train A travels at 60km/h, and Train B travels at 80km/h toward each other. How long until they meet?\n",
        "1. Calculate the combined speed.\n",
        "2. Divide the distance by the combined speed to find the time.\"\"\"\n",
        "ask(cot)\n",
        "\n",
        "# ðŸ§ª 5. Role Prompting\n",
        "# ðŸ“ Assign a role to shape response style\n",
        "ask(\"As a friendly teacher, explain in simple terms: What is a neural network?\")\n",
        "\n",
        "# ðŸ§ª 6. Custom Style Prompt\n",
        "# ðŸ“ Specify a tone for the response\n",
        "ask(\"Write a professional email response to: 'hey, i need help with my code asap'.\")\n",
        "\n",
        "# ðŸ§ª 7. JSON Format Output Prompt\n",
        "# ðŸ“ Request structured output (simplified for flan-t5-base)\n",
        "ask(\"List 3 cities with their countries in JSON format. Example: [{'city': 'Paris', 'country': 'France'}].\")\n",
        "\n",
        "# ðŸ§ª 8. Creative Prompt (Simplified)\n",
        "# ðŸ“ Simple creative task suited for flan-t5-base\n",
        "ask(\"Write a short sentence describing artificial intelligence in a futuristic tone.\")\n",
        "\n",
        "# ---\n",
        "# ðŸ“š Tips for Using This Cheatsheet\n",
        "# 1. Run each prompt in Colab to see how flan-t5-base responds.\n",
        "# 2. Experiment by tweaking prompts (e.g., add more examples, change instructions).\n",
        "# 3. Note: flan-t5-base is small and may struggle with complex tasks. For better results, try 'google/flan-t5-large' (if Colab memory allows).\n",
        "# 4. Save this notebook in Colab for future reference!\n",
        "\n",
        "# ðŸš€ Next Steps\n",
        "# - âœ… Run this notebook in Colab and save it.\n",
        "# - Explore HuggingFace Transformers 101 to learn more about LLMs.\n",
        "# - Learn LLM evaluation to assess model performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zdNt3f8bau25",
        "outputId": "f5da1efd-c31d-4333-a10b-e8d62966c937"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt:\n",
            "Translate to French: I love machine learning.\n",
            "\n",
            "Response:\n",
            "J'aime l'apprentissage de la machine.\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Translate to emoji:\n",
            "\"I love you\" -> â¤ï¸\n",
            "\"Good job\" -> ðŸ‘\n",
            "\"I'm angry\" -> ðŸ˜£\n",
            "Task: Translate \"I'm happy\" to emoji.\n",
            "\n",
            "Response:\n",
            "I'm happy\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Summarize in one sentence: Transformers are models that use self-attention to understand sentence context and are widely used in NLP tasks.\n",
            "\n",
            "Response:\n",
            "Understand transformers.\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Solve step by step: Two trains are 420km apart. Train A travels at 60km/h, and Train B travels at 80km/h toward each other. How long until they meet?\n",
            "1. Calculate the combined speed.\n",
            "2. Divide the distance by the combined speed to find the time.\n",
            "\n",
            "Response:\n",
            "Train A travels at 60km / h, so Train B travels at 80km / h, so Train A travels at 60km / h + 80km / h = 120km / h. Together, Train A and Train B travel at 120km / h + 80km / h = 180km / h. Together, Train A and Train B travel at 180km / h + 80km / h = 220km / h. Together, Train A and Train B travel at 220km / \n",
            "\n",
            "\n",
            "Prompt:\n",
            "As a friendly teacher, explain in simple terms: What is a neural network?\n",
            "\n",
            "Response:\n",
            "A neural network is a type of computer network.\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Write a professional email response to: 'hey, i need help with my code asap'.\n",
            "\n",
            "Response:\n",
            "Hello, I'd like to ask if you could help me with my code. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having a hard time figuring out what to do. I'm having \n",
            "\n",
            "\n",
            "Prompt:\n",
            "List 3 cities with their countries in JSON format. Example: [{'city': 'Paris', 'country': 'France'}].\n",
            "\n",
            "Response:\n",
            "['city': 'Paris', 'country': 'France']\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Write a short sentence describing artificial intelligence in a futuristic tone.\n",
            "\n",
            "Response:\n",
            "artificial intelligence in a futuristic tone\n",
            "\n"
          ]
        }
      ]
    }
  ]
}